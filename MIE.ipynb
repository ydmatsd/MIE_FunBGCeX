{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22806d5-fe34-4af6-bfeb-f3a3bd27b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Requirements\n",
    "- Biopython\n",
    "- HMMER (Version 3.4 tested; \"hmmpress\" and \"hmmscan\" need to be on the system $PATH)\n",
    "- DIAMOND (Version 2.1.8 tested; \"diamond\" needs to be on the system $PATH)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a887c4a-5858-49a9-856b-3a3097ce0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "import zipfile\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from Bio import SearchIO\n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830499f0-4b5e-416c-8404-dbe9f297b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4.2.1, Step 3\n",
    "Rename downloaded GenBank files and copy them to a single directory.\n",
    "Note: The unzipped directory (\"ncbi_dataset\") needs to be placed in the same directory as this Notebook.\n",
    "\"\"\"\n",
    "gbk_dir = \"gbk_files\"\n",
    "os.makedirs(gbk_dir,exist_ok=True)\n",
    "gbks = glob.glob(\"ncbi_dataset/**/genomic.gbff\",recursive=True)\n",
    "for gbk in gbks:\n",
    "    seq_records = SeqIO.parse(open(gbk),\"genbank\")\n",
    "    for record in seq_records:\n",
    "        fungus = record.annotations['organism'].replace(\" \",\"_\")\n",
    "        break\n",
    "    shutil.copy(gbk, os.path.join(gbk_dir,f\"{fungus}.gbff\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d2137-5002-42bf-b192-1ca0950de9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4.2.2, Step 1\n",
    "Extract Pyr4 homologues from BGCs that encode a Pyr4 homomolue and an additional core enzyme as a FASTA file (\"proteins.fasta\")\n",
    "\"\"\"\n",
    "fasta = open(\"proteins.fasta\",\"w\")\n",
    "homologue_list = []\n",
    "\n",
    "bgc_gbks = glob.glob(\"results/all_clusters/**/*.gbk\",recursive=True)\n",
    "for gbk in bgc_gbks:\n",
    "    core_list = []\n",
    "    seq_record = SeqIO.read(open(gbk),\"genbank\")\n",
    "    for feature in seq_record.features:\n",
    "        if feature.type == \"CDS\":\n",
    "            try:\n",
    "                core = feature.qualifiers[\"core\"][0].split(\";\")[0]\n",
    "                if core not in core_list:\n",
    "                    core_list.append(core)\n",
    "            except:\n",
    "                pass\n",
    "    if len(core_list) > 1:\n",
    "        for feature in seq_record.features:\n",
    "            if feature.type == \"CDS\":\n",
    "                try:\n",
    "                    if \"Pyr4\" in feature.qualifiers[\"Pfam\"][0]:\n",
    "                        locus_tag = feature.qualifiers[\"locus_tag\"][0]\n",
    "                        feature_seq = feature.qualifiers[\"translation\"][0].replace(\"-\",\"\")\n",
    "                        fasta.write(f\">{locus_tag}\\n\")\n",
    "                        fasta.write(f\"{feature_seq}\\n\")\n",
    "                        homologue_list.append([locus_tag,feature_seq,gbk])\n",
    "                except:\n",
    "                    pass\n",
    "fasta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1321e-295e-4e77-ae03-907d7eb96b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4.2.2, Step 2\n",
    "Extract Pyr4 homologues from the FunBGCs database\n",
    "Note: This step requires the FASTA file (\"proteins.fasta\") created in the previous step.\n",
    "\"\"\"\n",
    "def runHMMpress(input_file):\n",
    "    subprocess.run([\"hmmpress\",input_file],stdout=subprocess.DEVNULL)\n",
    "def runHMMscan(input_file,output_file,database,Evalue):\n",
    "    subprocess.run([\"hmmscan\",\"--domtblout\",output_file,\"-E\",Evalue,\"--domE\",\n",
    "                    Evalue,database,input_file],stdout=subprocess.DEVNULL)\n",
    "def makeDIAMONDdb(fasta,database):\n",
    "    subprocess.run([\"diamond\",\"makedb\",\"--in\",fasta,\"--db\",database],stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)\n",
    "def RunDIAMOND(fasta,database,output_file,max_target_seqs,max_hsps):\n",
    "    max_target_seqs = str(max_target_seqs)\n",
    "    max_hsps = str(max_hsps)\n",
    "    subprocess.run([\"diamond\",\"blastp\",\"--query\",fasta,\"--db\",database,\n",
    "                    \"--out\",output_file,\"--outfmt\",\"5\",\"--max-target-seqs\",max_target_seqs,\n",
    "                    \"--max-hsps\",max_hsps],stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)\n",
    "\n",
    "temp_dir = \"temp\"\n",
    "os.makedirs(temp_dir,exist_ok=True)\n",
    "\n",
    "#Download Pyr4.hmm and all_proteins.fa and copy them to the temp directory\n",
    "hmm_url = \"https://personal.cityu.edu.hk/ymatsuda/funbgcs/funbgcs/HMM.zip\"\n",
    "# hmm_url = \"http://staffweb1.cityu.edu.hk/ymatsuda/funbgcs/funbgcs/HMM.zip\" #use this URL if the first one does not work\n",
    "proteins_url = \"https://personal.cityu.edu.hk/ymatsuda/funbgcs/funbgcs/all_proteins.fa\"\n",
    "# proteins_url = \"http://staffweb1.cityu.edu.hk/ymatsuda/funbgcs/funbgcs/all_proteins.fa\" #use this URL if the first one does not work\n",
    "\n",
    "response = requests.get(hmm_url)\n",
    "zip_file_path = \"HMM.zip\"\n",
    "with open(zip_file_path, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "hmm_file = \"Pyr4.hmm\"\n",
    "shutil.copy(os.path.join(extracted_folder, hmm_file), f\"temp/{hmm_file}\")\n",
    "\n",
    "response2 = requests.get(proteins_url)\n",
    "with open(\"temp/all_proteins.fa\", \"wb\") as file:\n",
    "    file.write(response2.content)\n",
    "\n",
    "os.remove(zip_file_path)\n",
    "shutil.rmtree(extracted_folder)\n",
    "\n",
    "#Perform hmmscan analysis against all proteins in the FunBGCs database\n",
    "runHMMpress(f\"temp/{hmm_file}\")\n",
    "\n",
    "hmmscan_input = \"temp/all_proteins.fa\"\n",
    "hmmscan_output = \"temp/hmmscan.txt\"\n",
    "hmmscan_database = f\"temp/{hmm_file}\"\n",
    "runHMMscan(hmmscan_input,hmmscan_output,hmmscan_database,\"1e-5\")\n",
    "\n",
    "hit_list = []\n",
    "for qresult in SearchIO.parse(hmmscan_output, 'hmmscan3-domtab'):\n",
    "        for i in range(len(qresult.hits)):\n",
    "            hit_list.append(qresult.id)\n",
    "\n",
    "#Create a FASTA file with known Pyr4 homologues\n",
    "homologues_fasta = open(\"known_homologues.fasta\",\"w\")\n",
    "all_prot_list = [line for line in open(\"temp/all_proteins.fa\",\"r\")]\n",
    "for i in range(len(all_prot_list)):\n",
    "    if all_prot_list[i].startswith(\">\"):\n",
    "        prot_name = all_prot_list[i].replace(\">\",\"\").replace(\"\\n\",\"\")\n",
    "        if prot_name in hit_list:\n",
    "            homologues_fasta.write(all_prot_list[i])\n",
    "            homologues_fasta.write(all_prot_list[i+1])\n",
    "homologues_fasta.close()\n",
    "\n",
    "#Remove duplicated sequences\n",
    "known_prot = \"known_homologues.fasta\"\n",
    "diamond_database = \"temp/known_homologues\"\n",
    "makeDIAMONDdb(known_prot,diamond_database)\n",
    "\n",
    "extracted_prot = \"proteins.fasta\"\n",
    "diamond_output = \"temp/diamond_result.xml\"\n",
    "RunDIAMOND(extracted_prot,diamond_database,diamond_output,1,1)\n",
    "\n",
    "duplicated_proteins = []\n",
    "blast_records = NCBIXML.parse(open(diamond_output))\n",
    "for blast_record in blast_records:\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            query = blast_record.query\n",
    "            blast_hit = alignment.title.replace(\" \",\"\")\n",
    "            identity = 100*hsp.identities/len(hsp.match)\n",
    "            if identity > 90:\n",
    "                duplicated_proteins.append(query)\n",
    "\n",
    "original_fasta_list = [line for line in open(\"proteins.fasta\",\"r\")]\n",
    "with open(\"temp/proteins_.fasta\",\"w\") as fa:\n",
    "    for i in range(len(original_fasta_list)):\n",
    "        if original_fasta_list[i].startswith(\">\"):\n",
    "            prot_name = original_fasta_list[i].replace(\">\",\"\").replace(\"\\n\",\"\")            \n",
    "            if prot_name not in duplicated_proteins:\n",
    "                fa.write(original_fasta_list[i])\n",
    "                fa.write(original_fasta_list[i+1])\n",
    "\n",
    "#Remove duplicated sequences from the FASTA file for known proteins\n",
    "known_prot = \"known_homologues.fasta\"\n",
    "diamond_database = \"temp/known_homologues\"\n",
    "makeDIAMONDdb(known_prot,diamond_database)\n",
    "diamond_output = \"temp/diamond_result.xml\"\n",
    "RunDIAMOND(known_prot,diamond_database,diamond_output,20,1)\n",
    "\n",
    "duplicated_proteins = []\n",
    "blast_records = NCBIXML.parse(open(diamond_output))\n",
    "for blast_record in blast_records:\n",
    "    sublist = []\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            query = blast_record.query\n",
    "            blast_hit = alignment.title.replace(\" \",\"\")\n",
    "            identity = 100*hsp.identities/len(hsp.match)\n",
    "            if query != blast_hit and identity > 90:\n",
    "                NewProtein = True\n",
    "                for item in duplicated_proteins:\n",
    "                    if query in item:\n",
    "                        NewProtein = False\n",
    "                        if blast_hit not in item:\n",
    "                            item.append(blast_hit)\n",
    "                if NewProtein:\n",
    "                    duplicated_proteins.append([query,blast_hit])\n",
    "\n",
    "ToBeDeleted = []\n",
    "for item in duplicated_proteins:\n",
    "    for i in range(1,len(item)):\n",
    "        ToBeDeleted.append(item[i])\n",
    "\n",
    "original_fasta_list = [line for line in open(known_prot,\"r\")]\n",
    "with open(\"temp/known_homologues_.fasta\",\"w\") as fa:\n",
    "    for i in range(len(original_fasta_list)):\n",
    "        if original_fasta_list[i].startswith(\">\"):\n",
    "            prot_name = original_fasta_list[i].replace(\">\",\"\").replace(\"\\n\",\"\")            \n",
    "            if prot_name not in ToBeDeleted:\n",
    "                fa.write(original_fasta_list[i])\n",
    "                fa.write(original_fasta_list[i+1])\n",
    "\n",
    "#Combine the two FASTA files\n",
    "extracted_prot = \"temp/proteins_.fasta\"\n",
    "known_prot = \"temp/known_homologues_.fasta\"\n",
    "combined_prot = \"combined.fasta\"\n",
    "\n",
    "with open(combined_prot,\"w\") as cp:\n",
    "    with open(extracted_prot,\"r\") as ep:\n",
    "        for line in ep:\n",
    "            cp.write(line)\n",
    "    with open(known_prot,\"r\") as kp:\n",
    "        for line in kp:\n",
    "            cp.write(line)\n",
    "\n",
    "shutil.rmtree(temp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
